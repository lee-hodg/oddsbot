from scrapy.spider import Spider
from scrapy.selector import Selector
from Bookies.items import EventItem2
from Bookies.loaders import EventLoader
from scrapy.contrib.loader.processor import TakeFirst
from scrapy import log
from scrapy.http import Request
from Bookies.help_func import linkFilter
import re
import json
take_first = TakeFirst()


class BetathomeSpider(Spider):
    max_concurrent_requests = 1  # For linear testing
    name = "Betathome"

    # Visit the football homepage first
    def start_requests(self):
        yield Request(url='https://www.bet-at-home.com/en/sport',
                      callback=self.parseLeague)
    # def parseLeague(self, response):
    #     links = response.xpath('//li[@id="sport_1"]/ul/li/ul/li/a/@href').extract()

    #     # Filter links
    #     links = [link for link in links if not linkFilter(self.name, link)]

    #     # Get groupids from links
    #     gDicts = []
    #     p = re.compile("/en/sport/football/[a-zA-Z0-9-]+/[a-zA-Z0-9-]+/"
    #                    "(?P<eventGroupId>\d+)")
    #     for link in links:
    #         r = p.search(link)
    #         d = r.groupdict()
    #         gDicts.append(d)  # append dict like {'gid': u'10777'}

    #     # We have the problem that bet-at-home tracks, so leagues accumulate
    #     base_url = 'https://www.bet-at-home.com/svc/sport/AddRegion'
    #     # Build request for leagues
    #     # NB We are POSTing JSON here, use curl -d '{"eventGroupId":"4470"}'
    #     # Only asp cookie is essential
    #     # base_url = 'https://www.bet-at-home.com/svc/sport/ToggleEventGroup'
    #     headers = {'Content-Type': 'application/json; charset=utf-8',
    #                'Referer': 'https://www.bet-at-home.com/en/sport',
    #                'X-Requested-With': 'XMLHttpRequest'}
    #     for n, gDict in enumerate(gDicts):
    #         # log.msg('Calling leauge with gDict: %s \n with %s' % (gDict['eventGroupId'], links[n]))
    #         # stop = raw_input('e2c')
    #         loadedAll = False
    #         if n == len(gDicts)-1:
    #             # forloop last iteration
    #             loadedAll = True
    #         yield Request(url=base_url, headers=headers, method='POST',
    #                       body=json.dumps(gDict),
    #                       meta={'leagueLink': links[n], 'loadedAll': loadedAll},
    #                       callback=self.pre_parseData)

    def parseLeague(self, response):
        base_url = 'https://www.bet-at-home.com/svc/sport/AddSport'
        headers = {'Content-Type': 'application/json; charset=utf-8',
                   'Host': 'www.bet-at-home.com',
                   'Referer': 'https://www.bet-at-home.com/en/sport',
                   'X-Requested-With': 'XMLHttpRequest'
                   }

        yield Request(url=base_url, headers=headers, method='POST',
                      body=json.dumps({'sportId': '1'},
                      callback=self.pre_parseData)

    def pre_parseData(self, response):

        loadedAll = response.meta['loadedAll']
        log.msg('Preparsing events for league with link:%s' % response.meta['leagueLink'])
        log.msg('Finished loading? %s' % loadedAll)
        # stop = raw_input('e2c')
        if loadedAll:
            # Resp is JSON, albeit just one key!
            jsonResp = json.loads(response.body)
            sel = Selector(text=jsonResp['d'])  # Since str obj not Response
            base_url = 'https://www.bet-at-home.com'
            headers = {'Host': 'www.bet-at-home.com',
                       'Referer': 'https://www.bet-at-home.com/en/sport',
                       }
            moreLinks = sel.xpath('//table/tbody/tr/'
                                  'td[@class="ods-tbody-td ods-odd-additional"]/'
                                  'a/@href').extract()
            eventNames = sel.xpath('//table/tbody/tr/'
                                   'td[1]/text()').extract()
            log.msg('For the league with link:%s \n, we have %i more links and %i eventNames'
                    '. The eventNames are: \n %s' % (response.meta['leagueLink'], len(moreLinks),
                                                     len(eventNames), ', '.join(eventNames))
                    )
            stop = raw_input('e2c')
            for link in set(moreLinks):
                yield Request(url=base_url+link, headers=headers, dont_filter=True,
                              callback=self.parseData)

    def parseData(self, response):

        log.msg('Going to parse data for URL: %s' % response.url[20:],
                level=log.INFO)

        l = EventLoader(item=EventItem2(), response=response)
        l.add_value('sport', u'Football')
        l.add_value('bookie', self.name)

        dateTime = take_first(response.xpath('//span[@class="h-fontWeightNormal h-fontSize-11-lineheight-13"]/'
                                             'text()').extract())
        dateTime = take_first(dateTime.split(','))
        l.add_value('dateTime', dateTime)

        eventName = take_first(response.xpath('//span[@class="s-selected h-fontSize-14-lineheight-18"]/'
                                              'text()').extract())
        if eventName:
            teams = eventName.lower().split(' - ')
            l.add_value('teams', teams)

        # Markets
        mkts = response.xpath('//div[@class="rB S22G h-bG-FFFFFF l-mb3 l-overflowHidden"]')
        allmktdicts = []
        regex = re.compile("betslip3.OnTipClick\((?P<jData>.+)\)")
        for mkt in mkts:
            marketName = take_first(mkt.xpath('table/thead/tr/'
                                              'td[starts-with(@class, "ods-header")]//text()').extract())
            if not marketName:
                log.msg('No marketName, extract from: \n %s' % mkt.xpath('table/thead').extract())
                stop = raw_input('e2c')
            if 'Under/Over' in marketName or 'Handicap' in marketName:
                # Get handicap type
                htype = take_first(mkt.xpath('table/tbody/tr/td[1]/text()').extract())
                # Extract contents of (..)
                b1 = htype.find('(')
                b2 = htype.find(')')
                marketName += ' ' + htype[b1+1: b2]
            mDict = {'marketName': marketName, 'runners': []}
            runners = mkt.xpath('table/tbody/tr/td[starts-with(@class'
                                ', "ods-tbody-td")]/a/@onclick').extract()
            for runner in runners:
                r = regex.search(runner)
                dataDic = r.groupdict()['jData']
                dataJSON = json.loads(dataDic)
                runnerName = dataJSON['TipName']
                price = dataJSON['Odd']
                mDict['runners'].append({'runnerName': runnerName,
                                         'price': str(price),
                                         })
            allmktdicts.append(mDict)

        # Some Betathome specific formatting
        for mkt in allmktdicts:
            if mkt['marketName'] == 'Tip':
                mkt['marketName'] = 'Match Odds'
            for runner in mkt['runners']:
                if runner['runnerName'] == u'1':
                    runner['runnerName'] = 'HOME'
                elif runner['runnerName'] == u'2':
                    runner['runnerName'] = 'AWAY'
                elif runner['runnerName'] == u'X':
                    runner['runnerName'] = 'DRAW'

        # Add markets
        l.add_value('markets', allmktdicts)

        # Load item
        return l.load_item()

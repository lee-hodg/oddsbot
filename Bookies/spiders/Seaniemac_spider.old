from scrapy.conf import settings
from scrapy.spider import Spider
from scrapy.selector import Selector
from Bookies.items import EventItem
from scrapy.http import Request
import datetime, re
import dateutil.parser #since they use ordinal date 1st, 2nd..
import os
LOG_DIR = settings['LOG_DIR']

#%m %d, we will standardise bookie formating like that.
today = datetime.datetime.now()

#Another in the Jenningsbet family, identical to Apollobet.

class SeaniemacSpider(Spider):
    name = "Seaniemac"

    # The initial visit to /Betting will set X-mapping nd SessionId
    # cookies, but it is only when the sports tab is clicked that it calls
    # the js function ShowSports('') and in turn this sets cookie with
    # SetCookie func seensplash-sports=1 with exp date of 30 days
    start_urls = ['http://www.seaniemac.com/Betting'] 

    #you must retain the name 'parse' with basic spider!   
    def parse(self, response):
        # set the seen-splash cookie
        yield Request(url="http://www.seaniemac.com/Betting",
                               cookies={'seensplash-sports': '1'},
                               headers= {'Referer':'http://www.seaniemac.com/Betting'},
                               callback=self.pre_parse_countries)


    def pre_parse_countries(self, response):  
        #make request for league links
       
        # what is time here? prob in future?
        base_url =  'http://www.seaniemac.com/SportsBook/GetMenuItem'
        GETstr = '?navigationID=127797.1&level=2&name=A%20-%20Z&parentName=23.1&parentNames=Football/&parentIds=23.1,'
        headers= { 'Referer': 'http://www.seaniemac.com/Betting/Football?navigationid=top,23.1&time=164909',
                   'X-Requested-With': 'XMLHttpRequest'}

        #scrapy seems to now take care of seensplash-sports cookie and the __RequestVerificationToken_Lw__ cookie
        yield Request(url=base_url+GETstr,
                               #cookies={'seensplash-sports': '1'},
                               headers= headers,
                               callback=self.parse_countries)

    def parse_countries(self, response):  
       
        sel = Selector(response)

        #get js onclick methods e.g.
        # u"expandMenu('127875.1','3','England','A - Z','Football/A_-_Z/','23.1,127797.1,')" 	
        # expandMenu(navID, menuLevel, name, parentName, parentNames, parentsIds) (see sportsbook.js?vers2.1)
	country_methods = sel.xpath('//ul[@id="leftNav"]//li/span/a/@onclick').extract()

        #use regex to get the desired params from the onClicks, and put into nice dict
        p=re.compile(r"expandMenu\(\'(?P<navID>.+)\',\'(?P<menuLevel>.+)\',\'(?P<name>.+)\',\'(?P<parentName>.+)\',\'(?P<parentNames>.+)\',\'(?P<parentIDs>.+)\'\)")
        countryList = []
        for c in country_methods:
            m = p.match(c)
            country = {}
            country['navID'] = m.group('navID')
            country['menuLevel'] = m.group('menuLevel')
            country['name'] = m.group('name')
            country['parentName'] = m.group('parentName')
            country['parentNames'] = m.group('parentNames')
            country['parentIDs'] = m.group('parentIDs')
            countryList.append(country)


        # for each country we make a further request to get submenu of leagues
        base_url = 'http://www.seaniemac.com/SportsBook/GetMenuItem'
        headers = {'Referer': 'http://www.seaniemac.com/Betting/Football?navigationid=top,23.1&time=164909',
                   'X-Requested-With': 'XMLHttpRequest'}
	for country in countryList:
            GETstr = '?navigationID='+country['navID']+'&level='+country['menuLevel']+'&name='+country['name']+'&'
            GETstr += 'parentName='+country['parentName']+'&parentNames='+country['parentNames']+'&parentIds='+country['parentIDs']
            yield Request(url=base_url+GETstr, headers=headers, callback=self.parse_leagues)

    def parse_leagues(self, response):  
       
        sel = Selector(response)

        # we could do a similar thing now to traverse all leagues, but the matches href is sufficient
        matches_link = sel.xpath('//ul[@id="leftNav"]//li/span/a/@href').extract()

        if matches_link:
            url = 'http://www.seaniemac.com'+matches_link[0]
            headers = {'Referer': 'http://www.seaniemac.com/Betting/Football?navigationid=top,23.1&time=164909'}
            yield Request(url=url, headers=headers, callback=self.parse_Data)


    def parse_Data(self, response):

        print "[INFO %s]: \033[7m Going to parse data for URL: %s \033[0m" % (self.name,response.url[20:])

        sel = Selector(response)

        tableRows = sel.xpath('//table[@class="markettable"]//tr')

        # For all rows under with no date will use latest blockdate,
        # single item list to match xpath extract
        blockdate = []
        items = []
        for row in tableRows:
            
            rowdate = row.xpath('td[@class="iconcell"]/text()').extract()
            if rowdate:
                 #update blockdate if it was a date head row
                 blockdate = rowdate
                 print '[INFO %s]: \033[7m  Updating blockdate: %s \033[0m' % (self.name,blockdate)
                 #wait=raw_input('ENTER TO CONT...')
                 continue
            else:
                # Else test if this is an 'event' row, using time as
                # criteria.
                #
               rowtime = row.xpath('td[@class="firstcol"]/text()').extract()
               if rowtime:
                       # we have an event

                       event=row

                       item = EventItem()
                       date = blockdate
                       time = rowtime

                       #eventName, get @title not text() as text is often abbreviated with ...
                       item['eventName'] = event.xpath('td[@class="secondcol"]/span/a/@title').extract()

                       # Remember xpath returns lists, so we
                       # must strip using code below, if non-zero
                       time = [x.strip() for x in time]
                       date = [x.strip() for x in date]

                       # Format date and time as desired 
                       # Seaniemac uses Saturday 29th of March 2014
                       if  "Tomorrow" in date:
                           tmoz = today + datetime.timedelta(days=1)
                           date = [tmoz.strftime('%m %d')]
                       elif  "Today" in date:
                           date = [today.strftime('%m %d')]
                       elif date != []:
                           #29th Mar
                           #remove ordinal suffix (see jenningsbet)
                           date_parsed = dateutil.parser.parse(date[0])
                           date = [date_parsed.strftime('%m %d')]

                       # Set date and time
                       item['eventDate'] = date
                       item['eventTime'] = time #time already 24hr for Seaniemac

                       # odds
                       item['odd1'] = event.xpath('td[@class="thirdcol"]/table/tr/td[@class="pricecol1"]/label/input/@value').extract()
                       item['odd3'] = event.xpath('td[@class="thirdcol"]/table/tr/td[@class="pricecol2"]/label/input/@value').extract() #draw
                       item['odd2'] = event.xpath('td[@class="thirdcol"]/table/tr/td[@class="pricecol3"]/label/input/@value').extract()

                       items.append(item)  #validate in pipelines.py

        return items



